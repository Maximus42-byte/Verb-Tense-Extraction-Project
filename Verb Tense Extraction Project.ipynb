{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Installing and importing libraries**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JBUpzjPWkmsj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox4OrzKzkfA7",
        "outputId": "c4d4f27d-1e38-4caa-f1bf-f757dea7dbb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hazm\n",
            "  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n",
            "\u001b[K     |████████████████████████████████| 316 kB 15.0 MB/s \n",
            "\u001b[?25hCollecting libwapiti>=0.2.1\n",
            "  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n",
            "\u001b[K     |████████████████████████████████| 233 kB 63.0 MB/s \n",
            "\u001b[?25hCollecting nltk==3.3\n",
            "  Downloading nltk-3.3.0.zip (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n",
            "Building wheels for collected packages: nltk, libwapiti\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394486 sha256=b26b1748fd86e0912082d782f4e0e9da9d51e97f216da26c32efb1a546a67c67\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n",
            "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154918 sha256=e7aff0113c20bbc0799120a4d9e5a8cbaab753fd7c738e521c17de17722217cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n",
            "Successfully built nltk libwapiti\n",
            "Installing collected packages: nltk, libwapiti, hazm\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.7\n",
            "    Uninstalling nltk-3.7:\n",
            "      Successfully uninstalled nltk-3.7\n",
            "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n"
          ]
        }
      ],
      "source": [
        "%pip install hazm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals\n",
        "from hazm import *\n",
        "import random\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import codecs\n",
        "import re"
      ],
      "metadata": {
        "id": "Lu-f10g1lWiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing"
      ],
      "metadata": {
        "id": "0-0h8dLulba5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process(text):\n",
        "  normalizer = Normalizer()\n",
        "  normalized = normalizer.normalize(text)\n",
        "  tokens = word_tokenize(normalized)\n",
        "  tokens_lem = [get_lemma_set(t) for t in tqdm.tqdm(tokens)]\n",
        "\n",
        "  return tokens_lem,tokens"
      ],
      "metadata": {
        "id": "oavdIdY7lXxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lemma_set(tok):\n",
        "    lemmatizer = Lemmatizer()\n",
        "    return lemmatizer.lemmatize(tok)"
      ],
      "metadata": {
        "id": "yjDroX6YliQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shenase_mazi = {\n",
        "    'م': 'اول شخص مفرد',\n",
        "    'ی': 'دوم شخص مفرد',\n",
        "    '': 'سوم شخص مفرد',\n",
        "    'ست': 'سوم شخص مفرد',\n",
        "    'یم': 'اول شخص جمع',\n",
        "    'ید': 'دوم شخص جمع',\n",
        "    'ند': 'سوم شخص جمع',\n",
        "}\n",
        "shenase_mozare = {\n",
        "    'م': 'اول شخص مفرد',\n",
        "    'ی': 'دوم شخص مفرد',\n",
        "    'د': 'سوم شخص مفرد',\n",
        "    'یم': 'اول شخص جمع',\n",
        "    'ید': 'دوم شخص جمع',\n",
        "    'ند': 'سوم شخص جمع',\n",
        "}\n",
        "\n",
        "s_mozare1 = r\"(د|ند|ید|یم|ی|م)\"\n",
        "mazi_sade_re= r\"\\b({past_stem})({s})\\b\"\n",
        "mazi_sade = f\"{mazi_sade_re}\"\n",
        "mazi_estemrary_re= r\"\\b[می|نمی].*({past_stem})({s})\\b\"\n",
        "mazi_estemrary = f\"{mazi_estemrary_re}\"\n",
        "# mazi_mostamar_re= r\"\\b[داشت]({s})[می].*({past_stem})({s})\\b\"\n",
        "mazi_mostamar_re= r\"\\b(داشت{s}).*[می|نمی].*({past_stem})({s})\\b\"\n",
        "mazi_mostamar = f\"{mazi_mostamar_re}\"\n",
        "mazi_baeid_re= r\"\\b({past_stem})[ه].*[بود]({s})\\b\"\n",
        "mazi_baeid = f\"{mazi_baeid_re}\"\n",
        "mazi_naghli_re= r\"\\b({past_stem})[ه].*[ا]({s})\\b\"\n",
        "mazi_naghli = f\"{mazi_naghli_re}\"\n",
        "hal_ekhbari_re= r\"\\b[می|نمی].*({present_stem})({s})\\b\"\n",
        "hal_ekhbari = f\"{hal_ekhbari_re}\"\n",
        "hal_eltazemi_re= r\"\\b[ب].*({present_stem})({s})\\b\"\n",
        "hal_eltazemi = f\"{hal_eltazemi_re}\"\n",
        "hal_mostamar_re= r\"\\b(دار{s}).*[می|نمی].*({present_stem})({s})\\b\"\n",
        "hal_mostamar = f\"{hal_mostamar_re}\"\n",
        "aiande_re = r\"\\b(خواه{s}).*({past_stem})\\b\"\n",
        "aiande = f\"{aiande_re}\""
      ],
      "metadata": {
        "id": "8vIm6r_6ll_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The main Process**"
      ],
      "metadata": {
        "id": "73kHIsKHmLLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"کیلومتر شمار نمی شمارد\"\n",
        "verbs_details = []\n",
        "tokens_lem , tokens = process(text)\n",
        "# print(tokens_lem)\n",
        "# print('\\n', tokens)\n",
        "verbs_lem = [(i, x) for (i, x) in enumerate(tokens_lem) if (re.search('.#.', x) != None)]\n",
        "\n",
        "counted = False\n",
        "verbs = []\n",
        "for j in range(len(verbs_lem)):\n",
        "    i, verb_lem = verbs_lem[j]\n",
        "    if re.match('داشت|دار', verb_lem) != None and (j+1) < len(verbs_lem) and ((verbs_lem[j+1][0]) == i+1):\n",
        "      current_verb = tokens[i] + \" \" + tokens[i+1]\n",
        "      counted = True\n",
        "      verbs.append((current_verb, verbs_lem[j+1][1]))\n",
        "    elif not counted:\n",
        "      current_verb = tokens[i]\n",
        "      verbs.append((current_verb, verb_lem))\n",
        "    else:\n",
        "      counted = False\n",
        "\n",
        "for current_verb, x in verbs:\n",
        "    details = {}\n",
        "    print(current_verb)\n",
        "    print(x)\n",
        "    if re.search('.#.', x) != None:\n",
        "        past_stem, present_stem = x.split('#')\n",
        "        if re.search(f'.?{past_stem}.?', current_verb):\n",
        "          if re.search('خواه', current_verb):\n",
        "            details['زمان'] = 'آینده'\n",
        "            details['بن فعل'] = past_stem\n",
        "            details['شخص'] = \"\"\n",
        "            details['نوع'] = \"\"\n",
        "            for s in shenase_mozare:\n",
        "              aiande_format = aiande.format(past_stem = details['بن فعل'], s=s)\n",
        "              if (re.match(aiande_format,current_verb)):\n",
        "                details['نوع'] = \"آینده ساده\"\n",
        "                details['شخص'] = shenase_mozare.get(s)\n",
        "          else:\n",
        "            details['زمان'] = 'گذشته'\n",
        "            details['بن فعل'] = past_stem\n",
        "\n",
        "            for s in shenase_mazi:\n",
        "              mazi_estemrary_format = mazi_estemrary.format(past_stem = details['بن فعل'], s=s)\n",
        "              mazi_mostamar_format = mazi_mostamar.format(past_stem = details['بن فعل'], s=s)\n",
        "              mazi_sade_format = mazi_sade.format(past_stem = details['بن فعل'], s=s)\n",
        "              mazi_baeid_format = mazi_baeid.format(past_stem = details['بن فعل'], s=s)\n",
        "              mazi_naghli_format = mazi_naghli.format(past_stem = details['بن فعل'], s=s)\n",
        "              if (re.match(mazi_estemrary_format, current_verb)):\n",
        "                details['نوع'] = \"گذشته استمراری\"\n",
        "                details['شخص'] = shenase_mazi.get(s)\n",
        "              elif (re.match(mazi_mostamar_format, current_verb)):\n",
        "                details['نوع'] = \"گذشته مستمر\"\n",
        "                details['شخص'] = shenase_mazi.get(s)\n",
        "              elif (re.match(mazi_sade_format, current_verb)):\n",
        "                details['نوع'] = \"گذشته ساده\"\n",
        "                details['شخص'] = shenase_mazi.get(s)\n",
        "              elif (re.match(mazi_baeid_format, current_verb)):\n",
        "                details['نوع'] = \"گذشته بعید\"\n",
        "                details['شخص'] = shenase_mazi.get(s)\n",
        "              elif (re.match(mazi_naghli_format, current_verb)):\n",
        "                details['نوع'] = \"گذشته نقلی\"\n",
        "                details['شخص'] = shenase_mazi.get(s)\n",
        "\n",
        "            # remaining = current_verb.split(f'{past_stem}')\n",
        "        elif re.search(f'.?{present_stem}.?', current_verb):\n",
        "            details['زمان'] = 'حال'\n",
        "            details['بن فعل'] = present_stem\n",
        "            details['شخص'] = \"\"\n",
        "            details['نوع'] = \"\"\n",
        "\n",
        "            for s in shenase_mozare:\n",
        "              hal_ekhbari_format = hal_ekhbari.format(present_stem = details['بن فعل'], s=s)\n",
        "              hal_eltazemi_format = hal_eltazemi.format(present_stem = details['بن فعل'], s=s)\n",
        "              hal_mostamar_format = hal_mostamar.format(present_stem = details['بن فعل'], s=s)\n",
        "\n",
        "              if (re.match(hal_ekhbari_format,current_verb)):\n",
        "                details['شخص'] = shenase_mozare.get(s)\n",
        "                details['نوع'] = \"حال اخباری\"\n",
        "              elif (re.match(hal_eltazemi_format,current_verb)):\n",
        "                details['شخص'] = shenase_mozare.get(s)\n",
        "                details['نوع'] = \"حال التزامی\"\n",
        "              elif (re.match(hal_mostamar_format,current_verb)):\n",
        "                details['شخص'] = shenase_mozare.get(s)\n",
        "                details['نوع'] = \"حال مستمر\"\n",
        "\n",
        "            # remaining = current_verb.split(f'{present_stem}')\n",
        "\n",
        "        verbs_details.append(details)\n",
        "\n",
        "for x in verbs_details:\n",
        "    print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g63bWqzal3O_",
        "outputId": "77f93fa9-6953-459b-aa4f-9f40bb372d0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00,  3.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "نمی‌شمارد\n",
            "شمرد#شمار\n",
            "{'زمان': 'حال', 'بن فعل': 'شمار', 'شخص': 'سوم شخص مفرد', 'نوع': 'حال اخباری'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GSzJsDwfmJCh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}